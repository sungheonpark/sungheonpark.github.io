<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Sungheon Park</title>
  
  <meta name="author" content="Sungheon Park">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Sungheon Park</name>
              </p>
              <p>I am a staff researcher at <a href="https://www.sait.samsung.co.kr/saithome/main/main.do">Samsung Advanced Institute of Technology (SAIT)</a>.
                Prior to joining SAIT, I completed my PhD at <a href="http://mipal.snu.ac.kr/index.php/Main_Page">Machine Intelligence and Pattern Analysis Lab</a>, Seoul National University, Korea.
              </p>

              <p style="text-align:center">
                <a href="mailto:sungheon.park@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_sungheonpark.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=VhvtBHkAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/sungheonpark/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/profile.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interest lies in computer vision and deep learning, with emphasis on 3D pose estimation and reconstruction of dynamic objects and scenes.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/PRN_ECCV.png' width="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Procrustean Regression Networks: Learning 3D Structure of Non-Rigid Objects from 2D Annotations</papertitle>
              <br>
              <strong>Sungheon Park*</strong>,
              <a href="http://vml.hanyang.ac.kr/people/minsik-lee/">Minsik Lee*</a>,
              <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
              <br>
							<em>ECCV</em>, 2020
              <br>
              <a href="https://arxiv.org/abs/2007.10961">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=kFcTKNr-Sws">video</a>
              /
              <a href="https://github.com/sungheonpark/PRN">code</a>
              <p></p>
              <p>Non-rigid structure from motion cost function is directly applied as a loss function of neural nets to learn 3D shapes from 2D inputs.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/IJCNN.gif' width="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Pose estimator and tracker using temporal flow maps for limbs</papertitle>
              <br>
              <a href="https://sites.google.com/site/jihyesarahwang/home">Jihye Hwang</a>,
              Jieun Lee,
              <strong>Sungheon Park</strong>,
              <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
              <br>
              <em>IJCNN</em>, 2019 (<strong>Honorable Mention Award</strong> in the <a href="https://posetrack.net/workshops/eccv2018/posetrack_eccv_2018_results.html">POSETRACK challenge</a> at ECCV 2018 workshops)
              <br>
              <a href="https://arxiv.org/abs/1905.09500">arXiv</a>
              <p></p>
              <p>A pose estimator and tracker based on Limb Flow Maps.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Sungheon_bmvc_2018.png' width="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>3D Human Pose Estimation with Relational Networks</papertitle>
              <br>
              <strong>Sungheon Park</strong>,
              <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
              <br>
              <em>BMVC</em>, 2018
              <br>
              <a href="http://arxiv.org/abs/1805.08961">arXiv</a>
              /
              <a href="http://www.youtube.com/watch?v=JIeDtnNLOdc">video</a>
              /
              <a href="http://github.com/sungheonpark/3D_HPE_RN">code</a>
              <p></p>
              <p>3D human pose estimator from 2D joint positions with robustness to missing joints.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Sungheon_ISMIR_2018.png' width="180">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Music Source Separation Using Stacked Hourglass Networks</papertitle>
              <br>
              <strong>Sungheon Park</strong>,
              Taehoon Kim,
              <a href="http://marg.snu.ac.kr/marg_people/">Kyogu Lee</a>,
              <a href="http://mipal.snu.ac.kr/index.php/Nojun_Kwak">Nojun Kwak</a>
              <br>
              <em>ISMIR</em>, 2018
              <br>
              <a href="http://arxiv.org/abs/1805.08559">arXiv</a>
              /
              <a href="http://youtu.be/oGHC0ric6wo">video</a>
              /
              <a href="http://github.com/sungheonpark/music_source_sepearation_SH_net">code</a>
              <p></p>
              <p>CNNs for human pose estimation even works well with music source separation.</p>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Source code for this website was stolen from <a href="https://jonbarron.info">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
